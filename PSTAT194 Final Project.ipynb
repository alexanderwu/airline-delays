{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSTAT 194 Final Project: Predicting Flight Delays\n",
    "## Team: Walk in the Spark\n",
    "* Andrew Zhang\n",
    "* Wendy Gao\n",
    "* Alex Wu\n",
    "* Shon Inouye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing SQL Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data from parquet file\n",
    "flight_df = sqlCtx.read.parquet(\"/mnt/data/flight_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+-------+--------------+-------------------+--------------+--------+-----------------+---------------+-----+\n",
      "|MONTH|DAY|DAY_OF_WEEK|AIRLINE|ORIGIN_AIRPORT|SCHEDULED_DEPARTURE|SCHEDULED_TIME|DISTANCE|SCHEDULED_ARRIVAL|DEPARTURE_DELAY|DELAY|\n",
      "+-----+---+-----------+-------+--------------+-------------------+--------------+--------+-----------------+---------------+-----+\n",
      "|    4| 13|          1|      9|             6|               1327|         134.0|     867|             1641|          -10.0|    0|\n",
      "|    1| 13|          2|      5|            49|               1235|          65.0|     223|             1340|            0.0|    0|\n",
      "|    1| 11|          7|      9|            72|               1950|          74.0|     228|             2104|           13.0|    1|\n",
      "|    9|  2|          3|      1|            10|               1835|         285.0|    1947|             2020|            8.0|    1|\n",
      "+-----+---+-----------+-------+--------------+-------------------+--------------+--------+-----------------+---------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use OneHotEncoder to map categorical variables to binary vectors\n",
    "cat_columns = ['MONTH','DAY','DAY_OF_WEEK','AIRLINE','ORIGIN_AIRPORT']\n",
    "encoders = [OneHotEncoder(inputCol=column, outputCol=column+\"_vec\") for column in cat_columns]\n",
    "pipelineOHE = Pipeline(stages=encoders)\n",
    "flight_df2 = pipelineOHE.fit(flight_df).transform(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+-------+--------------+-------------------+--------------+--------+-----------------+---------------+-----+--------------+---------------+---------------+--------------+------------------+\n",
      "|MONTH|DAY|DAY_OF_WEEK|AIRLINE|ORIGIN_AIRPORT|SCHEDULED_DEPARTURE|SCHEDULED_TIME|DISTANCE|SCHEDULED_ARRIVAL|DEPARTURE_DELAY|DELAY|     MONTH_vec|        DAY_vec|DAY_OF_WEEK_vec|   AIRLINE_vec|ORIGIN_AIRPORT_vec|\n",
      "+-----+---+-----------+-------+--------------+-------------------+--------------+--------+-----------------+---------------+-----+--------------+---------------+---------------+--------------+------------------+\n",
      "|    4| 13|          1|      9|             6|               1327|         134.0|     867|             1641|          -10.0|    0|(12,[4],[1.0])|(31,[13],[1.0])|  (7,[1],[1.0])|(14,[9],[1.0])|   (323,[6],[1.0])|\n",
      "|    1| 13|          2|      5|            49|               1235|          65.0|     223|             1340|            0.0|    0|(12,[1],[1.0])|(31,[13],[1.0])|  (7,[2],[1.0])|(14,[5],[1.0])|  (323,[49],[1.0])|\n",
      "+-----+---+-----------+-------+--------------+-------------------+--------------+--------+-----------------+---------------+-----+--------------+---------------+---------------+--------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a vector of features\n",
    "assembler = VectorAssembler(inputCols=['MONTH_vec', 'DAY_vec', 'DAY_OF_WEEK_vec','AIRLINE_vec',\n",
    "                                       'SCHEDULED_DEPARTURE', 'ORIGIN_AIRPORT_vec', 'SCHEDULED_TIME', 'DISTANCE', \n",
    "                                       'SCHEDULED_ARRIVAL'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply vector assembler to data\n",
    "transformed = assembler.transform(flight_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|DELAY|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(391,[4,25,44,59,...|\n",
      "|    0|(391,[1,25,45,55,...|\n",
      "|    1|(391,[1,23,59,64,...|\n",
      "|    1|(391,[9,14,46,51,...|\n",
      "|    1|(391,[4,15,48,64,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.select(['DELAY', 'features']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to RDD\n",
    "dataRDD = transformed.select(['DELAY','features']).rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map label to binary values, then convert to LabeledPoint\n",
    "lp = dataRDD.map(lambda row : (0 if row[0] == 0 else 1, Vectors.dense(row[1])))    \\\n",
    "            .map(lambda row : LabeledPoint(row[0], row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1327.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,134.0,867.0,1641.0]),\n",
       " LabeledPoint(0.0, [0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1235.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,65.0,223.0,1340.0])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data approximately into training (80%) and test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "split = lp.randomSplit([0.8, 0.2], 314)\n",
    "training = split[0]\n",
    "test = split[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "LR_model = LogisticRegressionWithLBFGS.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on training data\n",
    "LR_LAPtrain = training.map(lambda lp: (float(LR_model.predict(lp.features)), lp.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.620115374674\n"
     ]
    }
   ],
   "source": [
    "# Print training accuracy\n",
    "LR_accTrain = 1.0 * LR_LAPtrain.filter(lambda x:x[0] == x[1]).count()/training.count()\n",
    "print(LR_accTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "LR_LAP = test.map(lambda lp: (float(LR_model.predict(lp.features)), lp.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617390688116\n"
     ]
    }
   ],
   "source": [
    "# Print test accuracy\n",
    "LR_acc = 1.0 * LR_LAP.filter(lambda x:x[0] == x[1]).count()/test.count()\n",
    "print(LR_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "RF_model = RandomForest.trainClassifier(training, numClasses = 2,\n",
    "                                       categoricalFeaturesInfo = {}, \n",
    "                                       numTrees = 5, featureSubsetStrategy = \"auto\", \n",
    "                                       impurity = 'gini', maxDepth = 4, maxBins = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on training data\n",
    "RF_predtrain = RF_model.predict(training.map(lambda x: x.features))\n",
    "RF_LAPtrain = training.map(lambda lp: lp.label).zip(RF_predtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528185727377\n"
     ]
    }
   ],
   "source": [
    "# Print training accuracy\n",
    "RF_trainAcc = RF_LAPtrain.filter(lambda x: x[0] == x[1]).count() / float(training.count())\n",
    "print(RF_trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "RF_pred = RF_model.predict(test.map(lambda x: x.features))\n",
    "RF_LAP = test.map(lambda lp: lp.label).zip(RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536012094583\n"
     ]
    }
   ],
   "source": [
    "# Print test accuracy\n",
    "RF_testAcc = RF_LAP.filter(lambda x: x[0] == x[1]).count() / float(test.count())\n",
    "print(RF_testAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "DT_model = DecisionTree.trainClassifier(training, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxDepth=5, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on training data\n",
    "DT_predtrain = DT_model.predict(training.map(lambda x: x.features))\n",
    "DT_LAPtrain = training.map(lambda lp: lp.label).zip(DT_predtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608178443029\n"
     ]
    }
   ],
   "source": [
    "# Print training accuracy\n",
    "DT_trainAcc = DT_LAPtrain.filter(lambda x: x[0] == x[1]).count() / float(training.count())\n",
    "print(DT_trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "DT_pred = DT_model.predict(test.map(lambda x: x.features))\n",
    "DT_LAP = test.map(lambda lp: lp.label).zip(DT_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603878770699\n"
     ]
    }
   ],
   "source": [
    "cDT_testAcc = DT_LAP.filter(lambda x: x[0] == x[1]).count() / float(test.count())\n",
    "print(DT_testAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "GBT_model = GradientBoostedTrees.trainClassifier(training,\n",
    "                                             categoricalFeaturesInfo={}, numIterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on training data\n",
    "GBT_predtrain = GBT_model.predict(training.map(lambda x: x.features))\n",
    "GBT_LAPtrain = training.map(lambda lp: lp.label).zip(GBT_predtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBT_trainErr = GBT_LAPtrain.filter(\n",
    "    lambda lp: lp[0] == lp[1]).count() / float(training.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.611186173837\n"
     ]
    }
   ],
   "source": [
    "# Print training accuracy\n",
    "print('Training Accuracy = ' + str(GBT_trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "GBT_predtest = GBT_model.predict(test.map(lambda x: x.features))\n",
    "GBT_LAPtest = test.map(lambda lp: lp.label).zip(GBT_predtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.608957550847\n"
     ]
    }
   ],
   "source": [
    "# Print test accuracy\n",
    "GBT_testErr = GBT_LAPtest.filter(\n",
    "    lambda lp: lp[0] == lp[1]).count() / float(test.count())\n",
    "print('Test Accuracy = ' + str(GBT_testErr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(391,[4,25,44,59,...|\n",
      "|  0.0|(391,[1,25,45,55,...|\n",
      "|  1.0|(391,[1,23,59,64,...|\n",
      "|  1.0|(391,[9,14,46,51,...|\n",
      "|  1.0|(391,[4,15,48,64,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "flight_cv = transformed.select(['DELAY', 'features'])\n",
    "flight_cv = flight_cv.withColumnRenamed('DELAY', 'label')\n",
    "flight_cv = flight_cv.select(flight_cv.label.cast(DoubleType()).alias('label'), \n",
    "                                 'features')\n",
    "flight_cv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data approximately into training (80%) and test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cv, test_cv = flight_cv.randomSplit([0.8, 0.2], 314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "lr_k = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create grid of parameters\n",
    "grid_k = ParamGridBuilder().addGrid(lr_k.maxIter, [0, 1, 5, 10, 25]) \\\n",
    "                           .addGrid(lr_k.regParam, [0.1,0.01]) \\\n",
    "                           .addGrid(lr_k.fitIntercept, [False, True])\\\n",
    "                           .addGrid(lr_k.elasticNetParam, [0.0,0.3, 0.5,0.8, 1.0])\\\n",
    "                           .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator_k = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_lr = CrossValidator(estimator = lr_k, estimatorParamMaps = grid_k, evaluator = evaluator_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run cross-validation\n",
    "cvmodel_lr = cv_lr.fit(train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6659110102881041"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate tuned model on training data\n",
    "evaluator_k.evaluate(cvmodel_lr.transform(train_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6683368558266156"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate tuned model on test data\n",
    "evaluator_k.evaluate(cvmodel_lr.transform(test_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorIndexer, IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol = \"label\", \n",
    "                             outputCol = \"indexedLabel\").fit(flight_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                              outputCol=\"indexedFeatures\", \n",
    "                              maxCategories=4).fit(flight_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\",\n",
    "                               outputCol=\"predictedLabel\", \n",
    "                               labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_k = RandomForestClassifier(labelCol = \"indexedLabel\", \n",
    "                              featuresCol = \"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator_rf = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\",\n",
    "                                                 predictionCol=\"prediction\",\n",
    "                                                metricName=\"accuracy\")\n",
    "numFolds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create grid of parameters\n",
    "grid_k_rf = ParamGridBuilder().addGrid(rf_k.numTrees, [5,10,25])\\\n",
    "                           .addGrid(rf_k.maxDepth, [3, 5,10,15])\\\n",
    "                           .addGrid(rf_k.maxBins, [5, 10, 20, 30])\\\n",
    "                           .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline of transformers and estimators\n",
    "pipeline_rf = Pipeline(stages=[labelIndexer, \n",
    "                               featureIndexer,\n",
    "                               rf_k,\n",
    "                               labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treat pipeline as estimator in a CrossValidator instance.\n",
    "cv_rf = CrossValidator(estimator = pipeline_rf, \n",
    "                       estimatorParamMaps = grid_k_rf, \n",
    "                       evaluator = evaluator_rf, \n",
    "                       numFolds = numFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run cross-validation\n",
    "cvmodel_rf = cv_rf.fit(train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6441231233354545"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate tuned model on training data\n",
    "predictions_rf_train = cvmodel_rf.transform(train_cv)\n",
    "evaluator_rf.evaluate(predictions_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate tuned model on test data\n",
    "predictions_rf = cvmodel_rf.transform(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|           0.0|  0.0|(391,[1,13,47,51,...|\n",
      "|           0.0|  0.0|(391,[1,13,47,52,...|\n",
      "|           0.0|  0.0|(391,[1,13,47,54,...|\n",
      "|           1.0|  0.0|(391,[1,13,47,55,...|\n",
      "|           0.0|  0.0|(391,[1,13,47,58,...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf.select(\"predictedLabel\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260473800910258"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_rf.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "dt_k = DecisionTreeClassifier(labelCol = \"indexedLabel\",\n",
    "                              featuresCol = \"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create grid of parameters\n",
    "grid_k_dt = ParamGridBuilder().addGrid(dt_k.maxDepth, [3, 5,10,15])\\\n",
    "                           .addGrid(dt_k.maxBins, [5, 10, 20, 30, 35])\\\n",
    "                           .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline of transformers and estimators\n",
    "pipeline_dt = Pipeline(stages=[labelIndexer, \n",
    "                               featureIndexer, \n",
    "                               dt_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treat pipeline as estimator in a CrossValidator instance.\n",
    "cv_dt = CrossValidator(estimator = pipeline_dt, \n",
    "                       estimatorParamMaps = grid_k_dt, \n",
    "                       evaluator = evaluator_rf, \n",
    "                       numFolds = numFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run cross-validation\n",
    "cvmodel_dt = cv_dt.fit(train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate tuned model on training data\n",
    "predictions_dt_train = cvmodel_dt.transform(train_cv)\n",
    "evaluator_rf.evaluate(predictions_dt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate tuned model on test data\n",
    "predictions_dt = cvmodel_dt.transform(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(391,[1,13,47,51,...|\n",
      "|       0.0|         0.0|(391,[1,13,47,52,...|\n",
      "|       1.0|         0.0|(391,[1,13,47,54,...|\n",
      "|       1.0|         0.0|(391,[1,13,47,55,...|\n",
      "|       0.0|         0.0|(391,[1,13,47,58,...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_dt.select(\"prediction\", \"indexedLabel\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6143307270393278"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_rf.evaluate(predictions_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(flight_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(flight_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator_gbt = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", \n",
    "                                                  predictionCol=\"prediction\", \n",
    "                                                  metricName=\"accuracy\")\n",
    "numFolds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "gbt_k = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline of transformers and estimators\n",
    "pipeline_gbt = Pipeline(stages=[labelIndexer, \n",
    "                                featureIndexer, \n",
    "                                gbt_k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create grid of parameters\n",
    "grid_k_gbt = ParamGridBuilder().addGrid(gbt_k.maxIter, [5,10,20])\\\n",
    "                           .addGrid(gbt_k.maxDepth, [3,5,10,15])\\\n",
    "                           .addGrid(gbt_k.maxBins, [5, 10, 20])\\\n",
    "                           .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Treat pipeline as estimator in a CrossValidator instance.\n",
    "cv_gbt = CrossValidator(estimator = pipeline_gbt, \n",
    "                       estimatorParamMaps = grid_k_gbt, \n",
    "                       evaluator = evaluator_gbt, \n",
    "                       numFolds = numFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run cross-validation\n",
    "cvmodel_gbt = cv_gbt.fit(train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.670167\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned model on training data\n",
    "predictions_gbt_train = cvmodel_gbt.transform(train_cv)\n",
    "\n",
    "accuracy_gbt_train = evaluator_gbt.evaluate(predictions_gbt_train)\n",
    "print(\"Training Accuracy = %g\" % (accuracy_gbt_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.630412\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned model on test data\n",
    "predictions_gbt_test = cvmodel_gbt.transform(test_cv)\n",
    "\n",
    "accuracy_gbt_test = evaluator_gbt.evaluate(predictions_gbt_test)\n",
    "print(\"Test Accuracy = %g\" % (accuracy_gbt_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Accuracy</th>\n",
       "      <td>0.608178</td>\n",
       "      <td>0.611186</td>\n",
       "      <td>0.620115</td>\n",
       "      <td>0.528186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.603879</td>\n",
       "      <td>0.608958</td>\n",
       "      <td>0.617391</td>\n",
       "      <td>0.536012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Decision Trees  Gradient Boosted Trees  \\\n",
       "Training Accuracy        0.608178                0.611186   \n",
       "Test Accuracy            0.603879                0.608958   \n",
       "\n",
       "                   Logistic Regression  Random Forests  \n",
       "Training Accuracy             0.620115        0.528186  \n",
       "Test Accuracy                 0.617391        0.536012  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data={'Logistic Regression': [0.620115374674,0.617390688116],\n",
    "                             'Random Forests': [0.528185727377,0.536012094583],\n",
    "                             'Decision Trees': [0.608178443029,0.603878770699],\n",
    "                             'Gradient Boosted Trees': [0.611186173837,0.608957550847]},\n",
    "                       index={'Training Accuracy',\n",
    "                              'Test Accuracy'})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Gradient Boosted Trees</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Accuracy</th>\n",
       "      <td>0.626541</td>\n",
       "      <td>0.670167</td>\n",
       "      <td>0.665911</td>\n",
       "      <td>0.644123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Accuracy</th>\n",
       "      <td>0.614331</td>\n",
       "      <td>0.630412</td>\n",
       "      <td>0.668337</td>\n",
       "      <td>0.626047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Decision Trees  Gradient Boosted Trees  \\\n",
       "Training Accuracy        0.626541                0.670167   \n",
       "Test Accuracy            0.614331                0.630412   \n",
       "\n",
       "                   Logistic Regression  Random Forests  \n",
       "Training Accuracy             0.665911        0.644123  \n",
       "Test Accuracy                 0.668337        0.626047  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_kfold = pd.DataFrame(data={'Logistic Regression': [0.6659110102881041,0.6683368558266156],\n",
    "                             'Random Forests': [0.6441231233354545,0.6260473800910258],\n",
    "                             'Decision Trees': [0.6265408093520941,0.6143307270393278],\n",
    "                             'Gradient Boosted Trees': [0.670167,0.630412]},\n",
    "                       index={'Training Accuracy',\n",
    "                              'Test Accuracy'})\n",
    "results_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our best overall model is Cross-Validated Logistic Regression with an accuracy of 66.83%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
